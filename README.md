# ğŸ” Project VeracityStream: Problem Statement

## ğŸš¨ The Challenge (Problem Statement 3)
Generative AI models are widely used for research, learning, and decision-making. However, these models often generate **factually incorrect information** presented with high confidence.

A critical extension of this problem is the creation of **fake citations, non-existent references, and broken links**, which appear legitimate but cannot be verified. This makes it difficult for users to trust AI-generated content and may lead to:
* **Misinformation**
* **Legal Risks**
* **Ethical Concerns**

## ğŸ’¡ The Solution
Build a system that can **detect, flag, and verify** factual claims and citations generated by AI models, helping users distinguish between reliable and unreliable AI-produced information.
---
## ğŸ‘¥ Team: NITP | ğŸ” Project: VeracityStream

---

# ğŸ” VeracityStream  
> **Byte Quest: PS 03** | *Fighting AI Hallucinations with Real-Time Verification*

[![Flutter](https://img.shields.io/badge/Frontend-Flutter-02569B?logo=flutter&logoColor=white)](https://flutter.dev)
[![Python](https://img.shields.io/badge/Backend-Python_3.10+-3776AB?logo=python&logoColor=white)](https://www.python.org)
[![Status](https://img.shields.io/badge/Project_Status-Commit_7/8-brightgreen)](#)

---
# ğŸ’¡ Deployed Link
> **[ğŸ”— Access Project Drive (APK & Source)](https://drive.google.com/drive/folders/1c4LCgsUCGYf2QVPUdP9XZb0je2rBJB88?usp=sharing)**

| Resource | Description |
| :--- | :--- |
| ğŸ“± **Android APK** | Pre-built binary for manual testing and UI evaluation. |
| ğŸ¥ **Walkthrough** | A 2-minute demonstration of the full-stack verification flow. |
| ğŸ“‚ **Source Archive** | Complete repository backup for offline review. |
| ğŸ“„ **Setup Guide** | Step-by-step instructions for local FastAPI & Flutter execution. |

---

## ğŸš© The Challenge: AIâ€™s â€œConfidence Gapâ€

Generative AI models are widely used for research, learning, and decision-making.  
However, they often generate **factually incorrect information with high confidence**, leading to trust, legal, and ethical risks.

**VeracityStream** is an automated verification layer designed to address:

- **Fabricated Facts** â€“ Claims without empirical evidence  
- **Ghost Citations** â€“ Fake, broken, or non-existent references  
- **Misinformation Risks** â€“ Harm caused by unreliable AI-generated content  



## ğŸ§  System Overview

<p align="center">
  <img src="assets/veracitystream-architecture.png"
       alt="VeracityStream System Architecture"
       width="700">
</p>

---

## ğŸ“‚ Project Structure
* `veracity_app/`: Flutter frontend.
* `veracity_backend/`: Python FastAPI engine & NLP logic.
---

## ğŸ“‚ Project Structure (Frontend)

Implemented in **Commit 2**, the Flutter application follows a **feature-first architecture with MVVM-inspired separation**, ensuring scalability and clean state management.

```text
lib/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ constants/       # App-wide strings and veracity labels
â”‚   â”œâ”€â”€ theme/           # Material 3 theme with custom veracity colors
â”‚   â””â”€â”€ network/         # HTTP/Dio client configuration
â”œâ”€â”€ features/
â”‚   â””â”€â”€ verification/    # Core feature: AI text analysis & UI
â”‚       â”œâ”€â”€ models/      # Claim and source data models
â”‚       â”œâ”€â”€ view/        # VeracityHighlighter and result widgets
â”‚       â””â”€â”€ viewmodel/   # API communication and verification state
â””â”€â”€ main.dart            # App entry point and theme initialization
```

**Flow:**

1. User inputs AI-generated text or a URL  
2. Text is decomposed into individual factual claims  
3. Claims and citations are verified using academic and web sources  
4. Results are scored and visualized in a color-coded UI
---
## ğŸŒ System Architecture
The project follows a **Client-Server** architecture to ensure modularity and scalability:

1. **Frontend (Flutter)**: Captures user input and sends it via HTTP POST to the backend.
2. **Service Layer**: Handles JSON serialization and data modeling in Dart.
3. **Backend (FastAPI)**: Receives text, executes spaCy NLP decomposition, and pings citations.
4. **Scoring Engine**: Returns a weighted veracity score to the frontend.

---
## âš™ï¸ Technical Workflow
1. **Flutter Mobile**: Captures text and sends it to `10.0.2.2:8000/verify`.
2. **FastAPI Engine**: Uses **spaCy** to extract claims and **Regex** to find URLs.
3. **Audit System**: Pings URLs in parallel to check HTTP status.
4. **Scoring Logic**: Calculates a weighted score based on source authority (.gov, .edu).
---
### ğŸ“¡ Internal API: `POST /verify`
The Flutter app interacts with this primary endpoint:
* **Request**: `{ "text": "AI generated string" }`
* **Response**: Includes `veracity_score`, `total_claims`, and a detailed `audit` list of URLs.
---
## âœ¨ Core Features (Beta)
* **NLP Claim Decomposition**: Breaks long-form AI responses into individual factual units using spaCy.
* **Real-time Link Auditing**: Uses `requests` to ping generated citations and identify "Ghost Citations" (404s).
* **Confidence Mapping**: Differentiates between verified sources and hallucinated references.
---
## ğŸ§‘â€ğŸ’» Some Screeshots
<figure align="center">
  <img src="assets/image1.png" alt="Input text string" width="800">
  <figcaption><b>Fig 1: The input interface for AI-generated text analysis.</b></figcaption>
</figure>

<br>

<figure align="center">
  <img src="assets/image2.png" alt="Output" width="800">
  <figcaption><b>Fig 2: Color-coded veracity results highlighting factual accuracy.</b></figcaption>
</figure>
<br>

<figure align="center">
  <img src="assets/image4.png" alt="Output" width="400">
  <figcaption><b>Fig 3: App Screenshot.</b></figcaption>
</figure>


## âš–ï¸ Veracity Scoring Logic

To eliminate AI hallucinations, **VeracityStream** calculates a truthfulness score ($V_s$) for every input using a weighted multi-factor analysis:

$$V_s = (L \times 0.50) + (A \times 0.30) + (C \times 0.20)$$

| Factor | Weight | Metric | Description |
| :--- | :---: | :---: | :--- |
| **Link Integrity ($L$)** | **50%** | `HTTP 200 OK` | Validates that citations are not "Ghost Links" (fabricated URLs). |
| **Source Authority ($A$)** | **30%** | `Domain Trust` | Assigns higher confidence to `.gov`, `.edu`, and peer-reviewed sources. |
| **Citation Coverage ($C$)** | **20%** | `Claim Ratio` | Measures the density of verified claims vs. total assertions. |

> **Note:** A score below **40%** triggers a ğŸ”´ High Risk alert, while scores above **85%** are marked as ğŸŸ¢ Verified.

<figure align="center">
  <img src="assets/image3.png" alt="Input text string" width="800">
  <figcaption><b>Fig 4: Example output of a score.</b></figcaption>
</figure>


---
## ğŸ¯ Key Objectives & Impact

### âœ… Automated Claim Extraction
Breaks unstructured AI text into independent, testable factual units using NLP.

### ğŸ”— Citation Audit Engine
- Validates URLs in real time  
- Detects fake or broken references  
- Verifies metadata against academic databases  

### ğŸ¨ Semantic Veracity Mapping
A Flutter-based UI that highlights:
- ğŸŸ¢ Verified claims  
- ğŸŸ¡ Uncertain claims  
- ğŸ”´ False or unverifiable claims  

---

## ğŸ› ï¸ Tech Stack

### Frontend
- Flutter (Mobile & Web)

### Backend
- Python 3.10+
- FastAPI
- LangGraph

### Verification APIs
- OpenAlex (Academic search)
- Crossref (Citation metadata)
- SerpAPI (Web verification)

---
## âš™ï¸ Setup & Installation

### Backend (Python/FastAPI)
1. Navigate to the backend directory: `cd veracity_backend`
2. Create a virtual environment: `python3 -m venv venv`
3. Activate the environment: `source venv/bin/activate`
4. Install dependencies: `pip install -r requirements.txt`
5. Run the server: `python main.py`

### Frontend (Flutter)
1. Navigate to the app directory: `cd veracity_app`
2. Get packages: `flutter pub get`
3. **Important**: Ensure `api_service.dart` is set to `10.0.2.2` for Android Emulators.
4. Run the app: `flutter run`
---

## ğŸ“Š Success Metrics

- **Detection Accuracy:**  
  > 90% identification of fabricated citations and invalid references

- **Verification Latency:**  
  Under 3 seconds per factual claim

- **Source Reliability:**  
  Preference for peer-reviewed and authoritative sources

---

## ğŸš€ Build Milestones

- [x] Commit 1: Initial Vision & Strategic Roadmap  
- [x] Commit 2: Flutter Project Scaffolding & Theme  
- [x] Commit 3: Backend â€“ NLP Claim Extraction  
- [x] Commit 4: Citation Metadata Validator  
- [x] Commit 5: Real-Time Verification & Scoring API  
- [x] Commit 6: Flutter â†” Backend API Integration  
- [x] Commit 7: Flutter Veracity Highlight UI  
- [x] Commit 8: Final Polish & Documentation  

---

## ğŸ“Œ Vision

> *â€œTrust is the missing layer in AI outputs. VeracityStream makes truth visible.â€*
